<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
    
    </script>

    <script async defer src="https://buttons.github.io/buttons.js">
    </script>

  <title>Chenxin Li</title>
  
  <meta name="author" content="Chenxin Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- <link rel="stylesheet" type="text/css" href="stylesheet.css"> -->
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
  <!-- <link rel="icon" type="image/ipg" href="images/channels4_profile.jpg"> -->
  <link rel="icon" href="./images/channels4_profile.jpg"/>
  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@700&family=Noto+Sans:wght@400;500;600;700&display=swap">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2%;width:75%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chenxin Li</name>
              </p>
              <p> 
              </p>
                 <!-- I am a Ph.D. student in Computer Science at The Hong Kong Polytechnic University. -->
                 <!-- , advised by Prof. <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Lei Zhang. -->
            
                
                <!-- Currently, I am dedicated to exploring the potential of implicit neural representation and neural radiance fields -->
                <!-- , exploring how to make it work in not ideal scenarios
 in practice, e.g., extreme input, dynamic objects. -->
                <!-- Before that, I studied model and data-efficient algorithms. -->
                <!-- My research interest lies at computer vision and medical imaging analysis. -->
                <!-- <p> 
                </p> -->
                I am a Ph.D. student at
                <a href="https://www.cuhk.edu.hk/"> The Chinese University of Hong Kong (CUHK)</a>, advised by Prof. <a href="https://www.ee.cuhk.edu.hk/~yxyuan/" target="_blank">
                Yixuan Yuan</a>. 
                I received my M. Eng degree from Xiamen University, advised by Prof. <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a> and Prof. <a href="https://huangyue05.github.io/">Yue Huang</a>.
                I obtained the B. Eng degree from Xiamen University. 
                <p> 
                </p>

                <!-- My research interest centers around computational imaging, mid-level vision, and computational photography. 
                I have developed machine learning algorithms for image and 3D data processing, with applications ranging from mixed reality to natural science.
                My goal is to extend the boundary of visible reality for humans, designing physics-inspired machine learning algorithms that augment and unlock human abilities to perceive and create information. -->

                My research interest lies at machine learning and computer vision.
                <!-- and medical imaging analysis, -->
                <!-- aiming to enhance our ability to perceive, represent, and create information for the ever-changing world. -->
                Recently, I study how to promote downstream vision tasks by using vision and multi-modal foundation models.


                <blockquote>
                  <p><em>-- The enemy killing who you could have been is actually yourself. </em></p>
                  <!-- <footer>ÂêçË®Ä‰ΩúËÄÖ</footer> -->
                </blockquote>

                <!-- I am a senior staff research scientist at <a href="https://ai.google/research">Google Research</a> in <a href="https://en.wikipedia.org/wiki/One_Market_Plaza">San Francisco</a>, where I work on computer vision and machine learning.
              </p>
              <p>
                At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>. -->
              </p>
              <p style="text-align:center">
                <a href="mailto:chenxinli1996@gmail.com">
                  <!-- Email -->
                  <span class="icon"><i class="fa fa-envelope"></i></span>
                  <span><strong>Email</strong></span>
                </a> &nbsp/&nbsp
                
                <a href="data/Resume_Chenxin_Li.pdf">
                  <span class="icon"><i class="fa fa-sticky-note"></i></span>
                  <span><strong>CV</strong></span>
                </a> &nbsp/&nbsp

                <!-- <span class="icon"><i class="fa fa-sticky-note"></i></span>
                  <span><strong> <a href="data/Resume_Chenxin_Li.pdf">CV</a> </strong></span>   </a> &nbsp/&nbsp -->
                <!-- <a href="data/Resume_Chenxin_Li.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->

                <a href="https://scholar.google.com.hk/citations?user=yfptgYMAAAAJ&hl=zh-CN">
                  <span class="icon"><i class="ai ai-google-scholar ai-1x"></i></span>
                  <span><strong>Google Scholar</strong></span>
                </a> &nbsp/&nbsp

                <a href="https://github.com/XGGNet">
                  <span class="icon"><i class="fa fab fa-github"></i></span>
                  <span><strong>Github</strong></span>
                </a>
                
                <!-- <a href="https://scholar.google.com.hk/citations?user=yfptgYMAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp -->
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <!-- <a href="https://github.com/XGGNet">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:25%;max-width:40%">
              <!-- <a href="my_images/photo.jpg"> -->
                <img style="width:80%;max-width:80%" alt="profile photo" src="my_images/DSCF2107.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Latest News</heading>

            <p>
              <!-- [08/2022] Join <a href="https://www.mmlab-ntu.com/">Pico@ByteDance</a>! -->

              <ul class="b">
                <li>[07/2023] Invited talk at <a href="https://xiangli-shaun.github.io/AIxMed.html">AIxMed Seminar</a>, Massachusetts General Hospital and Harvard Medical School. 
                   Gratitude to Prof. <a href="https://xiangli-shaun.github.io/index.html">Xiang Li</a>.
                </li>
                <li>[07/2023] One paper accepted to ICCV 2023.</li>
                <!-- <li>[06/2023] Work as a RA at CUHK, supervised by Prof.
                  Yixuan Yuan.</li> -->
              </ul class="b">

          </td>
        </tr>
      </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
        <tr>
          <td>
            <heading>Publications</heading>
            <br><h3>Conference Paper</h3>
          </td>
        </tr>
      </tbody></table>



        <!-- Publications -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <heading>Publications</heading>  -->
              <!-- <p> -->
              <!-- <subheading>Conference Paper</subheading> -->
              <!-- <br><h3>Conference Paper</h3>
            </td>
          </tr>
        </tbody>
      </table> -->
      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%; vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfsuper_image'>
                  <video  width=180 height="180" muted autoplay loop>
                <source src="videos/lego_res_resize160.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <!-- <img src='images/nerf_supervision.jpg' width="160"> -->
                <video  width=180 height=180 muted autoplay loop>
                  <source src="videos/lego_ren_resize160.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
              </div>
              <script type="text/javascript">
                function nerfsuper_start() {
                  document.getElementById('nerfsuper_image').style.opacity = "1";
                }

                function nerfsuper_stop() {
                  document.getElementById('nerfsuper_image').style.opacity = "0";
                }
                nerfsuper_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://xggnet.github.io/StegaNeRF/">
                <papertitle>StegaNeRF: Embedding Invisible Information within Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Chenxin Li*</strong>,
              <a href="https://brandonyfeng.github.io/">Brandon Y. Feng*</a>,
              <a href="https://zhiwenfan.github.io/">Zhiwen Fan*</a>, 
              <a href="https://paulpanwang.github.io/"> Panwang Pan</a>, 
              <a href='https://express.adobe.com/page/CAdrFMJ9QeI2y/'> Zhangyang Wang</a> 
              <!-- Brandon Y. Feng*,
              Zhiwen Fan*, 
              Panwang Pan, 
              Zhangyang Wang -->
              (* Equal Contribution)
              <br>
              <em>International Conference on Computer Vision (ICCV), 2023 </em>
              <br> 
							<a href="https://xggnet.github.io/StegaNeRF/">[Page]</a> 
							<a href="https://arxiv.org/abs/2212.01602">[ArXiv]</a> 
							<a href="https://youtu.be/sFdZU2dpqUw">[Video]</a> 
							<a href="https://github.com/XGGNet/StegaNeRF">[Code]</a> 
							<!-- <a href="https://colab.research.google.com/drive/13ISri5KD2XeEtsFs25hmZtKhxoDywB5y?usp=sharing">colab</a>				 -->
              <!-- <img src="https://img.shields.io/github/stars/XGGNet/StegaNeRF?style=social"> -->
              <!-- <img src="https://img.shields.io/github/forks/paulpanwang/Gen6DNeRF?style=social"> -->
              <p></p>
              <p> An initial exploration of instilling customizable, imperceptible, and recoverable information to NeRF renderings, with minimal impact to the rendered images.</p>
            </td>
          </tr>

          
					
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="samurai2_stop()" onmouseover="samurai2_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='samurai_image2'>
                  <img src='my_images/KCD-2.png'  width="180" ></div>
                <img src='my_images/KCD-1.png' width="180" >
              </div>
              <script type="text/javascript">
                function samurai2_start() {
                  document.getElementById('samurai_image2').style.opacity = "1";
                }

                function samurai2_stop() {
                  document.getElementById('samurai_image2').style.opacity = "0";
                }
                samurai2_stop() 
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.05409">
                <papertitle>Knowledge Condensation Distillation</papertitle>
              </a>
              <br>
              <strong>Chenxin Li</strong>,
              <a href="https://lmbxmu.github.io/">Mingbao Lin</a>, 
              Zhiyuan Ding,
              Nie Lin,
              Yihong Zhuang,
              <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>, 
              <a href="https://huangyue05.github.io/">Yue Huang</a>,
              <a href="https://scholar.google.com/citations?user=iYEcVaAAAAAJ&hl=zh-CN">Liujuan Cao</a>
              <br>
              European Conference on Computer Vision (<em>ECCV</em>), 2022
              <br>
              <!-- <a href="https://markboss.me/publication/2022-samurai/">project page</a> /
              <a href="https://www.youtube.com/watch?v=LlYuGDjXp-8">video</a> /
              <a href="https://arxiv.org/abs/2205.15768">arXiv</a> -->
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136710019.pdf">[PDF]</a> 
                <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136710019-supp.pdf">[Supp]</a> 
              <a href="https://arxiv.org/abs/2207.05409">[ArXiv]</a> 
              <a href="https://github.com/dzy3/KCD">[Code]</a>
              <!-- <img src="https://img.shields.io/github/stars/dzy3/KCD?style=social"> -->
              <p></p>
              <p>
              An iterative optimization framework for simultaneous model distillation and knowledge condensation.
              </p>
            </td>
          </tr>		
    
          <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='samurai_image'>
                  <img src='my_images/GVS-2.png' width="180"></div>
                <img src='my_images/GVS-1.png' width="180">
              </div>
              <script type="text/javascript">
                function samurai_start() {
                  document.getElementById('samurai_image').style.opacity = "1";
                }

                function samurai_stop() {
                  document.getElementById('samurai_image').style.opacity = "0";
                }
                samurai_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2009.05722">
                <papertitle>Generator Versus Segmentor: Pseudo-healthy Synthesis</papertitle>
              </a>
              <br>
              <a href="https://www.researchgate.net/profile/Zhang-Yunlong-3">Yunlong Zhang*</a>, 
              <strong>Chenxin Li*</strong>, 
              Xin Lin, 
              <!-- Liyan Sun,  -->
              <a href="https://scholar.google.com/citations?user=5UDCaIAAAAAJ&hl=en">Liyan Sun</a>, 
              Yihong Zhuang, 
              <!-- Yue Huang, 
              Xinghao Ding,  -->
              <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>, 
              <a href="https://huangyue05.github.io/">Yue Huang</a>,
              <a href="https://i.cs.hku.hk/~yzyu/">Yizhou Yu</a>
              (* Equal Contribution)
              <br>
              International Conference on Medical Image Computing and Computer Assisted Intervention (<em>MICCAI</em>), 2021
              <br>
              <!-- <a href="https://markboss.me/publication/2022-samurai/">project page</a> /
              <a href="https://www.youtube.com/watch?v=LlYuGDjXp-8">video</a> /
              <a href="https://arxiv.org/abs/2205.15768">arXiv</a> -->
              <a href="https://link.springer.com/content/pdf/10.1007/978-3-030-87231-1_15.pdf">[PDF]</a> 
              <a href="https://arxiv.org/abs/2009.05722">[ArXiv]</a> 
              <a href="https://github.com/Au3C2/GVS">[Code]</a>
              <!-- <img src="https://img.shields.io/github/stars/Au3C2/GVS?style=social"> -->
              <p></p>
              <p>
                A novel adversarial training scheme of generator against segmentor for more accurate lesion attribution and pseudo-healthy synthesis.
            </td>
          </tr>		
          
          
          <tr onmouseout="pnf_stop()" onmouseover="pnf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
            <div class="two" id='pnf_image'>
              <img src='my_images/VM-2.png' width="180"></div>
            <img src='my_images/VM-1.png' width="180">
            </div>
            <script type="text/javascript">
            function pnf_start() {
              document.getElementById('pnf_image').style.opacity = "1";
            }
  
            function pnf_stop() {
              document.getElementById('pnf_image').style.opacity = "0";
            }
            pnf_stop()
            </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2103.09097">
            <papertitle>Consistent Posterior Distributions under Vessel-Mixing: A Regularization for Cross-Domain Retinal Artery/Vein Classification</papertitle>
            </a> <br>
              <strong>Chenxin Li</strong>, 
              <a href="https://www.researchgate.net/profile/Zhang-Yunlong-3">Yunlong Zhang</a>, 
              Zhehan Liang, 
              <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>, 
              <a href="https://huangyue05.github.io/">Yue Huang</a>
              <!-- <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>, 
              <a href="https://huangyue05.github.io/">Yue Huang</a> -->
            <br>
            IEEE International Conference on Image Processing (<em>ICIP</em>), 2021
            <br>
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9506148">[PDF]</a> 
            <a href="https://arxiv.org/abs/2103.09097">[ArXiv]</a> 
            <p>
            </p>
            <p>
            A task-driven self-supervised approach as Vessel-mixing for retinal vessel segmentation.
             <!-- as Vessel-Mixing. -->
            </p>
            </td>
            </tr> 

                      
          <tr onmouseout="survey_stop()" onmouseover="survey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='survey_image'>
                  <img src='my_images/HKD-1.png' width="180"></div>
                <img src='my_images/HKD-2.png' width="180">
              </div>
              <script type="text/javascript">
                function survey_start() {
                  document.getElementById('survey_image').style.opacity = "1";
                }

                function survey_stop() {
                  document.getElementById('survey_image').style.opacity = "0";
                }
                survey_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Hint-Dynamic Knowledge Distillation</papertitle>
              </a>
              <br>
							Yiyang Liu,
              <strong> Chenxin Li </strong>,  
              Xiaotong Tu,  
              <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>,  
              <a href="https://huangyue05.github.io/">Yue Huang</a>
              <!-- <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>, 
              <a href="https://huangyue05.github.io/">Yue Huang</a> -->
           
              <br>
							<em>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2023 </em>
              <br>

              <a href="https://arxiv.org/abs/2211.17059">[ArXiv]</a> 
              <!-- <a href="https://arxiv.org/abs/2205.15768">[code]</a> -->

              <p></p>
              <p>
                A meta-learning based dynamic distillation framework, motivated by the diverse guidance effect of different knowledge hints across the distillation procedure.
              </p>
            </td>
          </tr>


            						
          <tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dualfont_image'>
                  <img src='my_images/ULNA-2.png' width="180"></div>
                <img src='my_images/ULNA-1.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3459637.3482310">
                <papertitle>Unsupervised Large-Scale Social Network Alignment via Cross Network Embedding</papertitle>
              </a>
              <br>
              Zhehan Liang, 
              <a href="https://scholar.google.com.hk/citations?user=itezhEMAAAAJ&hl=en">Yu Rong</a>, 
              <strong> Chenxin Li </strong>, 
              <a href="https://www.researchgate.net/profile/Zhang-Yunlong-3">Yunlong Zhang</a>, 
              <a href="https://huangyue05.github.io/">Yue Huang</a>, 
              Tingyang Xu, 
              <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>, 
              <a href="https://ranger.uta.edu/~huang/">Junzhou Huang</a>
              <br>
              Conference on Information and Knowledge Management (<em>CIKM</em>), 2021
              <br>
              <a href="https://dl.acm.org/doi/abs/10.1145/3459637.3482310">[PDF]</a> 
              <a href="https://github.com/ZheHanLiang/LSNA">[Code]</a> 
              <!-- <img src="https://img.shields.io/github/stars/ZheHanLiang/LSNA?style=social"> -->
              <p></p>
              <p>
              An unsupervised large-scale network alignment framework leveraging the cross-network information of user profiles.

              </p>
            </td>
          </tr>

        </tbody>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
        <tr>
          <td>
            <!-- <heading>Publications</heading> -->
            <!-- <br> -->
            <h3>Journal Paper</h3>
          </td>
        </tr>
      </tbody></table>

     
          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <br><h3>Journal Paper</h3>
            </td>
          </tr>
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='my_images/UASS-2.png' width="180"></div>
                <img src='my_images/UASS-1.png' width="180">
              </div>
               <script type="text/javascript">
                function malle_start() {
                 document.getElementById('malle_image').style.opacity = "1";
                }


                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2105.14732">
                <papertitle>Hierarchical Deep Network with Uncertainty-aware Semi-supervised Learning for Vessel Segmentation</papertitle>
              </a>
              <br>
              <strong>Chenxin Li</strong>, 
              <a href="https://scholar.google.com.hk/citations?user=noVgEXEAAAAJ&hl=zh-CN">Wenao Ma</a>, 
               <a href="https://scholar.google.com/citations?user=5UDCaIAAAAAJ&hl=en">Liyan Sun</a>, <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>, <a href="https://huangyue05.github.io/">Yue Huang</a>, 
               Guisheng Wang, <a href="https://i.cs.hku.hk/~yzyu/">Yizhou Yu</a>
              <br>
              Neural Computing and Applications (<em>NCA</em>), 2021
              <br>
              <a href="https://link.springer.com/article/10.1007/s00521-021-06578-3">[PDF]</a> 
              <a href="https://arxiv.org/abs/2105.14732">[ArXiv]</a> 
              <a href="https://github.com/XGGNet/Vessel-Seg">[Code]</a>
              <!-- <img src="https://img.shields.io/github/stars/XGGNet/Vessel-Seg?style=social"> -->

              <p></p>
              <p>
              An uncertainty-aware self-training via decoupling the decision boundary and pseudo-label evaluation with uncertainty modeling.
              </p>
            </td>
          </tr>
					

          <tr onmouseout="npil_stop()" onmouseover="npil_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='npil_image'>
                  <img src='my_images/TA-2.png' width="180"></div>
                <img src='my_images/TA-1.png' width="180">
              </div>
              <script type="text/javascript">
                function npil_start() {
                  document.getElementById('npil_image').style.opacity = "1";
                }

                function npil_stop() {
                  document.getElementById('npil_image').style.opacity = "0";
                }
                npil_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2106.06908">
                <papertitle>Domain Generalization on Medical Imaging Classification using Episodic Training with Task Augmentation</papertitle>
              </a>
              <br>
              <strong>Chenxin Li</strong>, Qi Qi, <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>, <a href="https://huangyue05.github.io/">Yue Huang</a>, 
              <a href=" https://scholar.google.com/citations?user=3cAJWoIAAAAJ&hl=zh-CN">Dong Liang</a>,
              <a href="https://i.cs.hku.hk/~yzyu/">Yizhou Yu</a>
              <br>
							Computers in Biology and Medicine (<em>CBM</em>), 2021
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482521009380">[PDF]</a> 
              <a href="https://arxiv.org/abs/2106.06908">[ArXiv]</a> 
              <a href="https://github.com/XGGNet/Task-Aug">[Code]</a>
              <!-- <img src="https://img.shields.io/github/stars/XGGNet/Task-Aug?style=social"> -->
              <p></p>
              <p>
              A task augmentation strategy for meta-learning, motivated by the task overfitting problem on domain generalization.
              <!-- , which motivates a task augmentation to alleviate such issue on medical imaging classification. -->
              </p>
            </td>
          </tr>

          <tr onmouseout="flare_stop()" onmouseover="flare_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='flare_image'>
                  <img src='my_images/GCNDE-1.png' width="180"></div>
                <img src='my_images/GCNDE-2.png' width="180">
              </div>
              <script type="text/javascript">
                function flare_start() {
                  document.getElementById('flare_image').style.opacity = "1";
                }

                function flare_stop() {
                  document.getElementById('flare_image').style.opacity = "0";
                }
                flare_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2012.05440">
                <papertitle>Few-shot Medical Image Segmentation using a Global Correlation Network with Discriminative Embedding</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=5UDCaIAAAAAJ&hl=en">Liyan Sun*</a>, <strong>Chenxin Li*</strong>, <a href="https://scholar.google.com.hk/citations?user=k5hVBfMAAAAJ&hl=en">Xinghao Ding</a>, <a href="https://huangyue05.github.io/">Yue Huang</a>, Guisheng Wang,
              <a href="https://i.cs.hku.hk/~yzyu/">Yizhou Yu</a>, 
              <a href="http://www.columbia.edu/~jwp2128/">John Paisley</a>
               (* Equal Contribution)
              <br>
							Computers in Biology and Medicine (<em>CBM</em>), 2021
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S0010482521008611">[PDF]</a> 
              <a href="https://arxiv.org/abs/2012.05440">[ArXiv]</a> 
              <a href="https://github.com/XGGNet/GCN-DE">[Code]</a>
              <!-- <img src="https://img.shields.io/github/stars/XGGNet/GCN-DE?style=social"> -->
              <p></p>
              <p>
                Capturing the global correlation and discriminative embedding across the support and query samples.
              </p>
            </td>
          </tr>

        </tbody>
      </table>

        <br>
         <!-- <br>  -->
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:020px;width:100%;vertical-align:middle">
              <heading>Projects</heading> 
              <p class="w3-justify">
              </p>
          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Project</heading>
              </td>
            </tr>
          </tbody></table> -->
          <ul class="b">

              <details><summary><subheading><b>Embedding Information within Neural Radiance Fields</b></subheading></summary>
                <img style="width:20%;" src="videos/lego_ren.gif"> &nbsp &nbsp&nbsp&nbsp&nbsp <img style="width:20%;" src="videos/lego_res5.gif">&nbsp &nbsp&nbsp&nbsp&nbsp <img style="width:20%;" src="videos/lego_res.gif">&nbsp &nbsp&nbsp&nbsp&nbsp <img style="width:20%;" src="videos/lego_rec.gif">
                  <figcaption>  &nbsp &nbsp Fig1. Rendering Views &nbsp &nbsp &nbsp &nbsp &nbsp  Fig2. Residual Error (x5).  &nbsp &nbsp &nbsp &nbsp  &nbsp  Fig3. Residual Error (x25).  &nbsp &nbsp  Fig4. Recovered Customized Images
                  </figcaption>
                  <p class="w3-justify">
                    Recent advances in  Neural Radiance Field (NeRF) imply a future of widespread visual data distributions through sharing NeRF model weights. 
                    In <a style="color: #447ec9" href="https://xggnet.github.io/StegaNeRF/">StegaNeRF</a>,
                    we signify an initial exploration into the novel problem of instilling customizable, imperceptible, and recoverable information to NeRF renderings, with minimal impact to rendered images.
                    We sincerely hope this work can promote the concerns about the intellectual property of INR/NeRF.
                    </p>
        </details>

            <br>
            <details>
              <summary><subheading><b>Efficient Knowledge Distillation Algorithms</b></subheading></summary>
              <!-- <img style="width:96%;" src="images/cascade_costvolume_teaser.jpg"> -->
              <p class="w3-justify">
              <!-- <a style="color: #447ec9" href="https://live.huawei.com/huaweiconnect/meeting/cn/5872.html">Huawei Connect (HC) 2020</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub">MindSpore Hub</a> -->
              <img style="width:35%;" src="my_images/fig2_v8.png">  
              <!-- <img style="width:20%;" src="my_images/exp_value.png">  -->
              <img style="width:22%;" src="my_images/task4_mask_rotation_3.png">
               <img style="width:35%;" src="my_images/v11.png">
                  <figcaption>  &nbsp Fig1. Knowledge Condensation Distillation &nbsp &nbsp Fig2. Relation of Condensed Knowledge.  &nbsp &nbsp &nbsp Fig3. Hint-Dynamic Distillation.
                  </figcaption>
              </p>
              <p class="w3-justify">
                Knowledge distillation (KD) plays a key role in developing lightweight deep networks by transferring the dark knowledge from a high-capacity teacher network to strengthen a smaller student one. 
                In
                <a href=https://link.springer.com/chapter/10.1007/978-3-031-20083-0_2> KCD </a> (<strong>ECCV'22</strong>),
                we explore an efficient knowledge distillation framework by co-designing model distillation and knowledge condensation, 
                which dynamically identifies and summarizes the informative knowledge points as a compact knowledge set across the knowledge transfer.
                <!-- Please see <a href=https://link.springer.com/chapter/10.1007/978-3-031-20083-0_2><u>ECCV 2022</u></a> for more details.
                 -->
                <p>

                In <a href=https://arxiv.org/abs/2211.17059>HKD</a>, 
                we investigate the diverse guidance
                effect from the knowledge of teacher model in different instances and learning stages.
                The existing literature keeps the fixed learning fashion to handle these knowledge hints.
                In comparison, we present to leverage the merits of meta-learning to customize a specific distillation fashion for each instance adaptively and dynamically.
               

              </p>

          </details>

          <br>

          <details>
            <summary><subheading><b>Data-Efficient Learning for Medical Imaging Analysis</b><subheading></summary>

            <!-- <img style="width:96%;" src="images/floorplan_annotation.png"> -->
            <!-- <p class="w3-justify"> -->
            <!-- <a style="color: #447ec9" href="https://floorplancad.github.io/">Project Page</a> and <a style="color: #447ec9" href="https://www.aliyun.com/product/ai/HoloWatcher_Introduction">Product Page</a> -->
            <!-- </p> -->
            <img style="width:32%;" src="my_images/Fig12.png">  
            <!-- <img style="width:23%;" src="my_images/ÂõæÁâá5.png">  -->
            <img style="width:40%;" src="my_images/ÂõæÁâá9.png"> 
            <img style="width:20%;" src="my_images/ÂõæÁâá10.png">
            <br>
            <br>
                <figcaption>  &nbsp &nbsp Fig1. GVS for Pseudo-Healthy Synthesis &nbsp &nbsp &nbsp &nbsp &nbsp Fig2. Uncertainty-Aware Self-Training  &nbsp &nbsp&nbsp &nbsp&nbsp &nbsp &nbsp &nbsp  &nbsp&nbsp &nbsp  Fig3. Enhanced Feature by GCN-DE
            <p class="w3-justify">
              <!-- CAD symbol spotting can be use in architecture, engineering and construction (AEC) industries to accelerate the efficiency of 3D modeling from CAD drawings.
              <br>
              We release the first large-scale real-world dataset of over 10,000 CAD drawings with line-grained annotations (35 classes), covering various types of builds.
              We introduce the new task of <span style="color:red">Panoptic Symbol Spotting</span>, which is a relaxation of the traditional symbol spotting problem. It spots
              and parse both countable object instances (windows, doors, tables, etc.) and uncountable stuff (wall, railing, etc.) from CAD drawings,
              Moreover, we propose the Panoptic Quality (PQ) as the evaluation criteria of panotic symbol spotting results.
              <br> -->
              <strong>Pseudo-Healthy Synthesis:</strong> As a variant of style-transfer task, synthesizing the healthy counterpart from the lesion regions is a important problem in clinical practice.
              In <a href=https://arxiv.org/abs/2009.05722>GVS</a> (<strong>MICCAI'21</strong>), we leverage the more accurate lesion attribution by constructing an adversarial learning framework between the pseudo-healthy generator and lesion segmentor.
              <p> 
              <strong>Domain Adaptation/Generalization:</strong> 
              Generalizing the deep models trained on one data source to other datasets is essential issue in practical medical imaging analysis.
              We present a domain adaptive approach by leveraging the self-supervised strategy called <a href=https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9506148>Vessel-Mixing</a> (ICIP'21),
              which is driven by the geometry characteristics of retinal vessels.

              We also attempt tp address the domain generalization problem in medical imaging via <a href=https://www.sciencedirect.com/science/article/abs/pii/S0010482521009380>Task-Aug</a> (CBM'21). We investigate the neglected issue summarized as task over-fitting, that is, the meta-learning framework gets over-fitting to the simulated meta-tasks, and present a task augmentation strategy.

              <p> 
              <strong>Semi-Supervised Learning:</strong> 
              The existing semi-supervised methods mainly exploit the unlabeled data via a self-labeling strategy.
              In <a href=https://link.springer.com/article/10.1007/s00521-021-06578-3>UAST</a> (NCA'21), 
              we present to decouple the unreliable connect between the decision boundary learning and pseudo-label evaluation.
              We instead leverage an uncertainty-aware self-training paradigm by modeling the accuracy of pseudo-labels via uncertainty modeling.
              <p> 
              <strong>Few-shot Learning:</strong> 
              Existing few-shot segmentation methods tend to fail in the incongruous foreground regions of support and query images.
              We present a few-shot learning method called <a href=https://www.sciencedirect.com/science/article/pii/S0010482521008611>GCN-DE</a> (CBM'21) which leverages a global correlation capture and discriminative embedding to address the above issue.

        </details>
        <!-- <br> -->
           <!-- <p>
            <p> -->
            <!-- <p> -->
              <!-- <br> -->
             <!--           CopyRight-->
                      <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                          <tbody>
               <p style="text-align:right;">Modified from <a href="https://jonbarron.info/">Jon Barron</a></p>
                          </tbody>
                      </table> -->
              
                </td>
              </tr>
            </table>

        
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Professional Activities</heading>
                <p><h3>Conference Reviewer</h3> 
                  <ul class="b">
                    <li>International Conference on Learning Representations (ICLR), 2024</li>
                    <p>    
                <li>Conference on Neural Information Processing Systems (NeurIPS), 2023</li>
                <p>
                  <li>International Conference on Computer Vision (ICCV), 2023</li>
                <p>
                  <li>ACM Multimedia (ACM MM), 2023</li>
                <p>
                  <li>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2023</li>
              </ul class="b">
                <p><h3>Journal Reviewer</h3> 
                  <ul class="b">
                <li>Pattern Recognition (PR)
                <p>
                <li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
                <p>
                <li>Neural Computing and Applications (NCAA)</li>
                </ul class="b">
    
                

          <br>
             <p>
              <p>
              <p>
                <br>
               <!--           CopyRight-->
                        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                            <tbody>
                 <p style="text-align:right;">Modified from <a href="https://jonbarron.info/">Jon Barron</a></p>
                            </tbody>
                        </table>
                
                  </td>
                </tr>
              </table>
  

        
          </body>
          
          </html>
          
